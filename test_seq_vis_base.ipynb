{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"../utils\")\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import src.datasets.cityscapes_loader as cityscapes_loader\n",
    "import utils.train_eval as train_eval\n",
    "import importlib\n",
    "import visualizations as vis\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2975 train images\n",
      "Found 500 val images\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cityscapes_loader)\n",
    "\n",
    "is_sequence = True\n",
    "\n",
    "dataset_root_dir = \"/home/nfs/inf6/data/datasets/cityscapes/\"\n",
    "\n",
    "train_ds = cityscapes_loader.cityscapesLoader(root=dataset_root_dir, split='train', img_size=(512, 1024), is_transform=True, is_sequence=is_sequence)\n",
    "#val_ds = cityscapes_loader.cityscapesLoader(root=dataset_root_dir, split='val', img_size=(1024, 2048), is_transform=True, is_sequence=is_sequence)\n",
    "val_ds = cityscapes_loader.cityscapesLoader(root=dataset_root_dir, split='val', img_size=(512, 1024), is_transform=True, is_sequence=is_sequence)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=2, shuffle=True, drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(val_ds, batch_size=1, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(UNet(\n",
       "   (encoder): UNetEncoder(\n",
       "     (in_block): ConvBlock(\n",
       "       (0): ConvWithNorm(\n",
       "         (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (activation): ReLU(inplace=True)\n",
       "       )\n",
       "       (1): ConvWithNorm(\n",
       "         (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "         (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (activation): ReLU(inplace=True)\n",
       "       )\n",
       "     )\n",
       "     (downsample_blocks): ModuleList(\n",
       "       (0): DownsampleBlock(\n",
       "         (downsampling): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "         (conv_block): ConvBlock(\n",
       "           (0): ConvWithNorm(\n",
       "             (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (activation): ReLU(inplace=True)\n",
       "           )\n",
       "           (1): ConvWithNorm(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (activation): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): DownsampleBlock(\n",
       "         (downsampling): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "         (conv_block): ConvBlock(\n",
       "           (0): ConvWithNorm(\n",
       "             (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (batchnorm2d): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (activation): ReLU(inplace=True)\n",
       "           )\n",
       "           (1): ConvWithNorm(\n",
       "             (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (batchnorm2d): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (activation): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (decoder): UNetDecoder(\n",
       "     (upsample_blocks): ModuleList(\n",
       "       (0): UpsampleBlock(\n",
       "         (upsample): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "         (conv_block): ConvBlock(\n",
       "           (0): ConvWithNorm(\n",
       "             (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (activation): ReLU(inplace=True)\n",
       "           )\n",
       "           (1): ConvWithNorm(\n",
       "             (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (batchnorm2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (activation): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): UpsampleBlock(\n",
       "         (upsample): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "         (conv_block): ConvBlock(\n",
       "           (0): ConvWithNorm(\n",
       "             (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (activation): ReLU(inplace=True)\n",
       "           )\n",
       "           (1): ConvWithNorm(\n",
       "             (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "             (batchnorm2d): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "             (activation): ReLU(inplace=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (out_block): Conv2d(64, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   )\n",
       " ),\n",
       " Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 2.9999999999999997e-05\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 79,\n",
       " [[1.184412683003042,\n",
       "   0.8516647646837889,\n",
       "   0.7417495770938946,\n",
       "   0.6861294011809784,\n",
       "   0.636661959649095,\n",
       "   0.6145068410668687,\n",
       "   0.5890461047998508,\n",
       "   0.5667359005474306,\n",
       "   0.5557605851226026,\n",
       "   0.5420629193612737,\n",
       "   0.5295713630130121,\n",
       "   0.5168576893944439,\n",
       "   0.5112998546132489,\n",
       "   0.4966943962135995,\n",
       "   0.4950936976544469,\n",
       "   0.4849851830570406,\n",
       "   0.4780632804773377,\n",
       "   0.4751907298654759,\n",
       "   0.4702457211219767,\n",
       "   0.4651367159743328,\n",
       "   0.4562843391824699,\n",
       "   0.4563925331646469,\n",
       "   0.44967037256842185,\n",
       "   0.44904779663878525,\n",
       "   0.44193962661607106,\n",
       "   0.44219660805099587,\n",
       "   0.4351537324498191,\n",
       "   0.430252375865849,\n",
       "   0.43025960010121683,\n",
       "   0.42458638653139086,\n",
       "   0.4219537765028339,\n",
       "   0.41878711060190904,\n",
       "   0.4171826114644914,\n",
       "   0.414919118942194,\n",
       "   0.4144683946350221,\n",
       "   0.4097788632918816,\n",
       "   0.40575178833941594,\n",
       "   0.40680978333885864,\n",
       "   0.4042249260969149,\n",
       "   0.3989255532802836,\n",
       "   0.39712972890881476,\n",
       "   0.3967005138562473,\n",
       "   0.39493541696270573,\n",
       "   0.39334088134733536,\n",
       "   0.39508660101553633,\n",
       "   0.3883595418079705,\n",
       "   0.38801643693591514,\n",
       "   0.38655279691094185,\n",
       "   0.3812242486234629,\n",
       "   0.38242190173785745,\n",
       "   0.38009687608376164,\n",
       "   0.37905690793955793,\n",
       "   0.3774635174473394,\n",
       "   0.37299137685854056,\n",
       "   0.3774327687909112,\n",
       "   0.37306636008327454,\n",
       "   0.3698239149387881,\n",
       "   0.3712880382788133,\n",
       "   0.3719461011333068,\n",
       "   0.36611275609537536,\n",
       "   0.36463960423604314,\n",
       "   0.3660607294832553,\n",
       "   0.36224182537715494,\n",
       "   0.36137686154402765,\n",
       "   0.3601981647723777,\n",
       "   0.3587635040563979,\n",
       "   0.35764927947505165,\n",
       "   0.33021905759542497,\n",
       "   0.3244949779792878,\n",
       "   0.322736753609588,\n",
       "   0.3221794596069754,\n",
       "   0.321342147455562,\n",
       "   0.32061504617754577,\n",
       "   0.32023148429185194,\n",
       "   0.3196350527002224,\n",
       "   0.318811108454721,\n",
       "   0.31848486279254007,\n",
       "   0.31726478429293087,\n",
       "   0.3183391073751257,\n",
       "   0.317534351553442],\n",
       "  [2.9958875026702882,\n",
       "   0.9820488033294678,\n",
       "   0.810578548669815,\n",
       "   0.7591998143196106,\n",
       "   0.7012375614643097,\n",
       "   0.6745423386096955,\n",
       "   0.622766637802124,\n",
       "   0.6342445828914642,\n",
       "   0.5997314941883087,\n",
       "   0.6041901149749755,\n",
       "   0.5717230269908905,\n",
       "   0.5664548070430756,\n",
       "   0.5515553467273712,\n",
       "   0.5580690457820893,\n",
       "   0.5422578626871108,\n",
       "   0.5474461858272552,\n",
       "   0.5209673765897751,\n",
       "   0.5014307172298431,\n",
       "   0.5162661418914795,\n",
       "   0.5146306195259094,\n",
       "   0.5248950221538544,\n",
       "   0.514312293291092,\n",
       "   0.5051750469207764,\n",
       "   0.5036759355068207,\n",
       "   0.48116825342178343,\n",
       "   0.5259393177032471,\n",
       "   0.47762339651584623,\n",
       "   0.5011986252069474,\n",
       "   0.4885657572746277,\n",
       "   0.469268824338913,\n",
       "   0.49408411467075347,\n",
       "   0.4846159819364548,\n",
       "   0.4770489567518234,\n",
       "   0.48268609201908114,\n",
       "   0.4697213343381882,\n",
       "   0.4743327651023865,\n",
       "   0.46684396016597746,\n",
       "   0.4850168319940567,\n",
       "   0.47593930971622467,\n",
       "   0.4758910893201828,\n",
       "   0.46515964150428774,\n",
       "   0.4678726999759674,\n",
       "   0.46103855323791504,\n",
       "   0.47006564486026764,\n",
       "   0.45725687301158907,\n",
       "   0.4478230949640274,\n",
       "   0.44942198741436007,\n",
       "   0.4668735846281052,\n",
       "   0.4733609529733658,\n",
       "   0.45681919646263125,\n",
       "   0.4595607690811157,\n",
       "   0.4551662360429764,\n",
       "   0.45149522626399996,\n",
       "   0.4564529641866684,\n",
       "   0.45669612228870393,\n",
       "   0.4354240862131119,\n",
       "   0.45389573502540587,\n",
       "   0.4575964105129242,\n",
       "   0.45948926341533664,\n",
       "   0.4450448491573334,\n",
       "   0.4559860385656357,\n",
       "   0.4484746806621552,\n",
       "   0.44873987865448,\n",
       "   0.4400410747528076,\n",
       "   0.4437041449546814,\n",
       "   0.4455056833028793,\n",
       "   0.4490738443136215,\n",
       "   0.43863224470615386,\n",
       "   0.4160889916419983,\n",
       "   0.4161549255847931,\n",
       "   0.4169984939098358,\n",
       "   0.41370146095752713,\n",
       "   0.414916005730629,\n",
       "   0.4164385530948639,\n",
       "   0.4199635396003723,\n",
       "   0.4184912328720093,\n",
       "   0.4119094016551971,\n",
       "   0.41696123909950256,\n",
       "   0.424822939991951,\n",
       "   0.41807214760780337],\n",
       "  [3.1248834133148193,\n",
       "   3.121392250061035,\n",
       "   3.0751254558563232,\n",
       "   3.1177124977111816,\n",
       "   2.874999523162842,\n",
       "   2.841341733932495,\n",
       "   2.868040084838867,\n",
       "   2.8332326412200928,\n",
       "   2.545405387878418,\n",
       "   2.5148184299468994,\n",
       "   2.7902674674987793,\n",
       "   2.6515917778015137,\n",
       "   2.59960675239563,\n",
       "   2.6027145385742188,\n",
       "   2.4913697242736816,\n",
       "   2.5611627101898193,\n",
       "   2.2488574981689453,\n",
       "   2.415715456008911,\n",
       "   2.267744302749634,\n",
       "   2.3015451431274414,\n",
       "   2.135420083999634,\n",
       "   2.248567819595337,\n",
       "   2.184016704559326,\n",
       "   2.3517608642578125,\n",
       "   2.2202062606811523,\n",
       "   1.9831035137176514,\n",
       "   2.268820285797119,\n",
       "   1.9801223278045654,\n",
       "   2.1146411895751953,\n",
       "   2.1995763778686523,\n",
       "   2.094621181488037,\n",
       "   1.9803836345672607,\n",
       "   1.9514803886413574,\n",
       "   1.9880125522613525,\n",
       "   1.9299657344818115,\n",
       "   1.9740421772003174,\n",
       "   1.8156362771987915,\n",
       "   1.9937255382537842,\n",
       "   1.755072832107544,\n",
       "   1.952130675315857,\n",
       "   1.8641979694366455,\n",
       "   1.9411131143569946,\n",
       "   1.8202834129333496,\n",
       "   1.7752350568771362,\n",
       "   1.7692697048187256,\n",
       "   2.0562961101531982,\n",
       "   1.7182198762893677,\n",
       "   1.7980839014053345,\n",
       "   1.7753535509109497,\n",
       "   1.7107770442962646,\n",
       "   2.0089735984802246,\n",
       "   1.6662983894348145,\n",
       "   1.5974376201629639,\n",
       "   1.7107406854629517,\n",
       "   1.837053656578064,\n",
       "   1.5898607969284058,\n",
       "   1.4415998458862305,\n",
       "   1.6734429597854614,\n",
       "   1.7101494073867798,\n",
       "   1.4597517251968384,\n",
       "   1.6643937826156616,\n",
       "   1.5585108995437622,\n",
       "   1.7397984266281128,\n",
       "   1.4899487495422363,\n",
       "   1.5734385251998901,\n",
       "   1.4013128280639648,\n",
       "   1.5175364017486572,\n",
       "   1.5951712131500244,\n",
       "   1.6485989093780518,\n",
       "   1.4436938762664795,\n",
       "   1.3210318088531494,\n",
       "   1.4541492462158203,\n",
       "   1.5285295248031616,\n",
       "   1.532947063446045,\n",
       "   1.4715303182601929,\n",
       "   1.5980074405670166,\n",
       "   1.3294671773910522,\n",
       "   1.9179575443267822,\n",
       "   1.4657058715820312,\n",
       "   1.577404260635376,\n",
       "   1.6119270324707031,\n",
       "   1.24448823928833,\n",
       "   1.571237325668335,\n",
       "   1.5849432945251465,\n",
       "   1.3958406448364258,\n",
       "   1.8274421691894531,\n",
       "   1.3995548486709595,\n",
       "   1.3757915496826172,\n",
       "   1.4306182861328125,\n",
       "   1.4934051036834717,\n",
       "   1.301132321357727,\n",
       "   1.5062706470489502,\n",
       "   1.6911401748657227,\n",
       "   1.4207981824874878,\n",
       "   1.4364230632781982,\n",
       "   1.7509729862213135,\n",
       "   1.6850110292434692,\n",
       "   1.6768699884414673,\n",
       "   1.4532983303070068,\n",
       "   1.3436245918273926,\n",
       "   1.388871431350708,\n",
       "   1.3101935386657715,\n",
       "   1.3443256616592407,\n",
       "   1.3371776342391968,\n",
       "   1.5235995054244995,\n",
       "   1.374008297920227,\n",
       "   1.3171114921569824,\n",
       "   1.1166834831237793,\n",
       "   1.546738862991333,\n",
       "   1.261779546737671,\n",
       "   1.6032525300979614,\n",
       "   1.6461312770843506,\n",
       "   1.134953498840332,\n",
       "   1.244279146194458,\n",
       "   1.2027379274368286,\n",
       "   1.3118414878845215,\n",
       "   1.6339914798736572,\n",
       "   1.2715203762054443,\n",
       "   1.1651017665863037,\n",
       "   1.5516694784164429,\n",
       "   1.7022898197174072,\n",
       "   1.2191344499588013,\n",
       "   1.1900534629821777,\n",
       "   1.1702961921691895,\n",
       "   1.2899730205535889,\n",
       "   1.1788716316223145,\n",
       "   1.2974214553833008,\n",
       "   1.2273274660110474,\n",
       "   1.1703150272369385,\n",
       "   1.2045223712921143,\n",
       "   1.5188828706741333,\n",
       "   1.4004063606262207,\n",
       "   1.4940876960754395,\n",
       "   1.3819901943206787,\n",
       "   1.338736653327942,\n",
       "   1.5033451318740845,\n",
       "   1.0845552682876587,\n",
       "   1.234154224395752,\n",
       "   1.4758999347686768,\n",
       "   1.2536271810531616,\n",
       "   1.0903842449188232,\n",
       "   1.2266765832901,\n",
       "   1.3964035511016846,\n",
       "   1.2744834423065186,\n",
       "   1.2774161100387573,\n",
       "   1.1710760593414307,\n",
       "   1.304978609085083,\n",
       "   1.2582497596740723,\n",
       "   1.3592331409454346,\n",
       "   1.2933827638626099,\n",
       "   1.0958170890808105,\n",
       "   1.1514616012573242,\n",
       "   1.0746946334838867,\n",
       "   1.3151706457138062,\n",
       "   1.0909584760665894,\n",
       "   1.4288661479949951,\n",
       "   1.4749077558517456,\n",
       "   1.263150930404663,\n",
       "   1.1233477592468262,\n",
       "   1.2628748416900635,\n",
       "   1.2311817407608032,\n",
       "   1.472795009613037,\n",
       "   1.5433804988861084,\n",
       "   1.1958134174346924,\n",
       "   1.5739238262176514,\n",
       "   1.1500217914581299,\n",
       "   1.3028324842453003,\n",
       "   1.1529176235198975,\n",
       "   1.088931918144226,\n",
       "   1.3436799049377441,\n",
       "   1.0688729286193848,\n",
       "   1.1424298286437988,\n",
       "   1.1609406471252441,\n",
       "   1.2914316654205322,\n",
       "   1.1599702835083008,\n",
       "   1.370789647102356,\n",
       "   1.3067395687103271,\n",
       "   1.3421351909637451,\n",
       "   1.1715275049209595,\n",
       "   1.3875067234039307,\n",
       "   1.1034730672836304,\n",
       "   1.1469662189483643,\n",
       "   1.4251399040222168,\n",
       "   1.3082547187805176,\n",
       "   1.15231454372406,\n",
       "   1.06703782081604,\n",
       "   1.208348274230957,\n",
       "   1.2450387477874756,\n",
       "   1.1131218671798706,\n",
       "   1.1285227537155151,\n",
       "   1.7911046743392944,\n",
       "   1.1512540578842163,\n",
       "   0.9536227583885193,\n",
       "   1.1728469133377075,\n",
       "   1.181530237197876,\n",
       "   1.2118726968765259,\n",
       "   1.2345081567764282,\n",
       "   1.3651036024093628,\n",
       "   1.1270338296890259,\n",
       "   1.2516956329345703,\n",
       "   1.5450531244277954,\n",
       "   1.3014706373214722,\n",
       "   0.994866132736206,\n",
       "   1.39364755153656,\n",
       "   1.2794309854507446,\n",
       "   1.2381724119186401,\n",
       "   1.224668264389038,\n",
       "   1.5204665660858154,\n",
       "   0.9440329074859619,\n",
       "   1.1743618249893188,\n",
       "   1.1505420207977295,\n",
       "   1.2043120861053467,\n",
       "   1.1243619918823242,\n",
       "   1.2717187404632568,\n",
       "   1.1202783584594727,\n",
       "   1.3346189260482788,\n",
       "   1.5359700918197632,\n",
       "   1.4229978322982788,\n",
       "   1.3725529909133911,\n",
       "   1.3098304271697998,\n",
       "   1.1541765928268433,\n",
       "   1.0999093055725098,\n",
       "   1.1890232563018799,\n",
       "   1.4736809730529785,\n",
       "   1.0493879318237305,\n",
       "   0.9537397623062134,\n",
       "   1.017935037612915,\n",
       "   1.029692530632019,\n",
       "   1.320432424545288,\n",
       "   1.3283820152282715,\n",
       "   1.019869089126587,\n",
       "   1.1408631801605225,\n",
       "   1.4806020259857178,\n",
       "   1.3047659397125244,\n",
       "   1.0570998191833496,\n",
       "   1.1173726320266724,\n",
       "   1.2946430444717407,\n",
       "   1.1469088792800903,\n",
       "   1.2495633363723755,\n",
       "   1.3070250749588013,\n",
       "   1.242760419845581,\n",
       "   1.693154215812683,\n",
       "   1.2148483991622925,\n",
       "   1.1354418992996216,\n",
       "   1.102369785308838,\n",
       "   1.2007538080215454,\n",
       "   1.0509434938430786,\n",
       "   1.2840619087219238,\n",
       "   0.9677218198776245,\n",
       "   1.3072781562805176,\n",
       "   1.4281717538833618,\n",
       "   1.1943511962890625,\n",
       "   1.1194955110549927,\n",
       "   1.3203107118606567,\n",
       "   1.1398078203201294,\n",
       "   1.1201509237289429,\n",
       "   1.1751409769058228,\n",
       "   1.347378134727478,\n",
       "   1.025897741317749,\n",
       "   1.03795325756073,\n",
       "   0.9358018040657043,\n",
       "   1.3194137811660767,\n",
       "   1.1259794235229492,\n",
       "   0.906826376914978,\n",
       "   1.0521355867385864,\n",
       "   1.0968842506408691,\n",
       "   1.1397461891174316,\n",
       "   0.9717628359794617,\n",
       "   1.0601507425308228,\n",
       "   1.0076489448547363,\n",
       "   1.0649863481521606,\n",
       "   1.4665040969848633,\n",
       "   0.826806902885437,\n",
       "   1.0651167631149292,\n",
       "   1.1885675191879272,\n",
       "   1.0991368293762207,\n",
       "   1.152923583984375,\n",
       "   0.8868539929389954,\n",
       "   1.1976823806762695,\n",
       "   1.2920591831207275,\n",
       "   1.070387840270996,\n",
       "   0.9369277358055115,\n",
       "   0.9782354235649109,\n",
       "   1.001133680343628,\n",
       "   1.1591838598251343,\n",
       "   0.8650398254394531,\n",
       "   1.163461685180664,\n",
       "   1.0414249897003174,\n",
       "   0.8838077187538147,\n",
       "   1.3623912334442139,\n",
       "   1.16312575340271,\n",
       "   1.0533432960510254,\n",
       "   0.9932888150215149,\n",
       "   0.9464708566665649,\n",
       "   0.8906044960021973,\n",
       "   1.0939366817474365,\n",
       "   1.1771783828735352,\n",
       "   0.9908921122550964,\n",
       "   1.395566463470459,\n",
       "   1.0858712196350098,\n",
       "   1.0854501724243164,\n",
       "   1.1235504150390625,\n",
       "   1.2693886756896973,\n",
       "   0.9588372707366943,\n",
       "   1.3238575458526611,\n",
       "   0.8498845100402832,\n",
       "   1.3026626110076904,\n",
       "   0.990719735622406,\n",
       "   1.0221439599990845,\n",
       "   1.0935494899749756,\n",
       "   0.9908636212348938,\n",
       "   1.328031063079834,\n",
       "   1.1577122211456299,\n",
       "   1.2563354969024658,\n",
       "   0.8122067451477051,\n",
       "   1.2824547290802002,\n",
       "   1.1666209697723389,\n",
       "   1.1852179765701294,\n",
       "   1.1644039154052734,\n",
       "   1.2785649299621582,\n",
       "   1.017417550086975,\n",
       "   1.156140923500061,\n",
       "   0.7581644058227539,\n",
       "   1.0102508068084717,\n",
       "   1.053083896636963,\n",
       "   1.2125407457351685,\n",
       "   1.5382708311080933,\n",
       "   1.1359282732009888,\n",
       "   0.9459702372550964,\n",
       "   1.071407675743103,\n",
       "   1.0484751462936401,\n",
       "   0.8148384690284729,\n",
       "   0.9476251006126404,\n",
       "   1.0259222984313965,\n",
       "   1.6437904834747314,\n",
       "   1.2534116506576538,\n",
       "   0.8787420392036438,\n",
       "   1.0577389001846313,\n",
       "   0.8709704875946045,\n",
       "   1.21097731590271,\n",
       "   1.0402119159698486,\n",
       "   1.019175410270691,\n",
       "   1.022892713546753,\n",
       "   0.9260276556015015,\n",
       "   1.1505247354507446,\n",
       "   1.009939432144165,\n",
       "   0.8993911743164062,\n",
       "   1.5608875751495361,\n",
       "   1.513138771057129,\n",
       "   1.054646372795105,\n",
       "   0.9981375336647034,\n",
       "   1.043816089630127,\n",
       "   1.5086474418640137,\n",
       "   1.0039931535720825,\n",
       "   1.296179175376892,\n",
       "   0.9508689641952515,\n",
       "   0.8588920831680298,\n",
       "   0.9324103593826294,\n",
       "   0.9612371921539307,\n",
       "   1.0598411560058594,\n",
       "   1.086265206336975,\n",
       "   0.9334102869033813,\n",
       "   1.0981616973876953,\n",
       "   1.1507035493850708,\n",
       "   1.070826530456543,\n",
       "   1.2249451875686646,\n",
       "   1.0079237222671509,\n",
       "   1.0526719093322754,\n",
       "   1.4344533681869507,\n",
       "   1.1430782079696655,\n",
       "   0.9909416437149048,\n",
       "   0.8812985420227051,\n",
       "   0.9235951900482178,\n",
       "   1.0135070085525513,\n",
       "   1.0167043209075928,\n",
       "   1.1126129627227783,\n",
       "   1.0439213514328003,\n",
       "   0.9845261573791504,\n",
       "   0.9747636318206787,\n",
       "   0.9897424578666687,\n",
       "   1.0593128204345703,\n",
       "   0.9413031935691833,\n",
       "   1.2137359380722046,\n",
       "   0.9710084199905396,\n",
       "   1.0650731325149536,\n",
       "   1.117151141166687,\n",
       "   1.0235856771469116,\n",
       "   0.8858687281608582,\n",
       "   1.0916759967803955,\n",
       "   1.1372723579406738,\n",
       "   1.0229191780090332,\n",
       "   0.8185907602310181,\n",
       "   1.017154335975647,\n",
       "   1.4600026607513428,\n",
       "   1.0565277338027954,\n",
       "   1.0909456014633179,\n",
       "   0.9922316074371338,\n",
       "   1.0153679847717285,\n",
       "   1.004186987876892,\n",
       "   0.7990976572036743,\n",
       "   1.0705252885818481,\n",
       "   0.8410424590110779,\n",
       "   0.9367936849594116,\n",
       "   1.1011130809783936,\n",
       "   0.8670651912689209,\n",
       "   1.0880160331726074,\n",
       "   0.9589276313781738,\n",
       "   1.0800546407699585,\n",
       "   0.9419070482254028,\n",
       "   1.3413546085357666,\n",
       "   1.2509185075759888,\n",
       "   1.0637431144714355,\n",
       "   1.11552095413208,\n",
       "   0.8421450853347778,\n",
       "   0.9832345247268677,\n",
       "   0.8294276595115662,\n",
       "   0.950740396976471,\n",
       "   0.9325438737869263,\n",
       "   0.9620840549468994,\n",
       "   1.3165665864944458,\n",
       "   1.231388807296753,\n",
       "   1.1907912492752075,\n",
       "   1.2136383056640625,\n",
       "   1.2395466566085815,\n",
       "   1.2059134244918823,\n",
       "   0.9255837798118591,\n",
       "   1.2000797986984253,\n",
       "   0.7996262311935425,\n",
       "   1.173760175704956,\n",
       "   0.8561798930168152,\n",
       "   0.9085972905158997,\n",
       "   0.9703938364982605,\n",
       "   1.0115585327148438,\n",
       "   1.2148358821868896,\n",
       "   1.4910887479782104,\n",
       "   0.9533135294914246,\n",
       "   1.2986794710159302,\n",
       "   0.9009271860122681,\n",
       "   1.0498194694519043,\n",
       "   0.8953807353973389,\n",
       "   1.0249980688095093,\n",
       "   1.4552106857299805,\n",
       "   1.2100893259048462,\n",
       "   1.0185065269470215,\n",
       "   0.9614220857620239,\n",
       "   1.0800034999847412,\n",
       "   0.7821667194366455,\n",
       "   1.1773422956466675,\n",
       "   0.9188622236251831,\n",
       "   1.1426938772201538,\n",
       "   1.1697801351547241,\n",
       "   0.8930482864379883,\n",
       "   0.8920127153396606,\n",
       "   1.0517680644989014,\n",
       "   0.7584016919136047,\n",
       "   0.9988296627998352,\n",
       "   0.9293811321258545,\n",
       "   0.8497143983840942,\n",
       "   0.8569706082344055,\n",
       "   1.1030997037887573,\n",
       "   1.0071510076522827,\n",
       "   1.0237131118774414,\n",
       "   0.9337887763977051,\n",
       "   1.1269840002059937,\n",
       "   1.026053547859192,\n",
       "   1.041577935218811,\n",
       "   0.891865074634552,\n",
       "   1.0267497301101685,\n",
       "   0.9776991009712219,\n",
       "   1.0623624324798584,\n",
       "   0.9274481534957886,\n",
       "   1.3162733316421509,\n",
       "   0.9924333691596985,\n",
       "   0.9792154431343079,\n",
       "   1.0253102779388428,\n",
       "   0.9884173274040222,\n",
       "   0.9180052876472473,\n",
       "   0.921151876449585,\n",
       "   0.8406643867492676,\n",
       "   1.123576045036316,\n",
       "   0.8633319139480591,\n",
       "   1.2088276147842407,\n",
       "   0.933234453201294,\n",
       "   0.9201142191886902,\n",
       "   1.383731722831726,\n",
       "   0.7665054202079773,\n",
       "   0.9914528131484985,\n",
       "   0.7146543264389038,\n",
       "   0.8606094121932983,\n",
       "   0.7572708129882812,\n",
       "   0.7930303812026978,\n",
       "   1.1307917833328247,\n",
       "   0.9471566081047058,\n",
       "   1.4809298515319824,\n",
       "   0.8763672709465027,\n",
       "   0.9148404598236084,\n",
       "   0.7431077361106873,\n",
       "   0.905182957649231,\n",
       "   0.9908886551856995,\n",
       "   0.9326794147491455,\n",
       "   1.0382189750671387,\n",
       "   0.9833975434303284,\n",
       "   0.9791544079780579,\n",
       "   0.7766280770301819,\n",
       "   0.8674505352973938,\n",
       "   1.1389760971069336,\n",
       "   1.0259093046188354,\n",
       "   1.214572548866272,\n",
       "   0.7534769773483276,\n",
       "   1.1676907539367676,\n",
       "   0.9907246232032776,\n",
       "   0.9103425741195679,\n",
       "   1.3988960981369019,\n",
       "   0.8817532658576965,\n",
       "   0.8915198445320129,\n",
       "   1.122087836265564,\n",
       "   1.0222762823104858,\n",
       "   1.04973566532135,\n",
       "   1.3688284158706665,\n",
       "   0.7640780210494995,\n",
       "   1.247429370880127,\n",
       "   0.8884660005569458,\n",
       "   0.8634390830993652,\n",
       "   0.9467536807060242,\n",
       "   0.8371888399124146,\n",
       "   0.89234858751297,\n",
       "   0.8919480443000793,\n",
       "   1.0047791004180908,\n",
       "   0.9672106504440308,\n",
       "   0.8217909932136536,\n",
       "   1.3933689594268799,\n",
       "   1.1427741050720215,\n",
       "   1.0779589414596558,\n",
       "   0.846716046333313,\n",
       "   0.9437905550003052,\n",
       "   0.7750040292739868,\n",
       "   0.7888726592063904,\n",
       "   0.9849303960800171,\n",
       "   0.8369314074516296,\n",
       "   0.9063872694969177,\n",
       "   1.1350404024124146,\n",
       "   0.8436471223831177,\n",
       "   0.8851648569107056,\n",
       "   0.8256510496139526,\n",
       "   0.8255947828292847,\n",
       "   0.9370067119598389,\n",
       "   0.7769101858139038,\n",
       "   0.9933828711509705,\n",
       "   1.1015191078186035,\n",
       "   1.0392369031906128,\n",
       "   1.0744380950927734,\n",
       "   0.9267897605895996,\n",
       "   0.9532253742218018,\n",
       "   0.8415234088897705,\n",
       "   1.0342789888381958,\n",
       "   0.7743013501167297,\n",
       "   0.842461109161377,\n",
       "   0.9440010786056519,\n",
       "   0.7265743017196655,\n",
       "   1.304347276687622,\n",
       "   1.1269477605819702,\n",
       "   1.0839871168136597,\n",
       "   0.9848087430000305,\n",
       "   0.695281445980072,\n",
       "   0.8376448750495911,\n",
       "   1.054290771484375,\n",
       "   1.0381032228469849,\n",
       "   1.3113117218017578,\n",
       "   1.101430892944336,\n",
       "   0.9669880867004395,\n",
       "   0.7808501720428467,\n",
       "   0.9772565364837646,\n",
       "   1.3193418979644775,\n",
       "   0.9728776812553406,\n",
       "   0.9828850626945496,\n",
       "   1.1144005060195923,\n",
       "   0.9670405387878418,\n",
       "   0.8426145315170288,\n",
       "   1.1173419952392578,\n",
       "   1.2673203945159912,\n",
       "   0.9935267567634583,\n",
       "   0.9397096633911133,\n",
       "   0.9302893877029419,\n",
       "   0.7973352670669556,\n",
       "   1.0604102611541748,\n",
       "   0.8564278483390808,\n",
       "   1.00972318649292,\n",
       "   1.2477257251739502,\n",
       "   1.0273184776306152,\n",
       "   1.0776033401489258,\n",
       "   0.957019031047821,\n",
       "   1.1077311038970947,\n",
       "   0.7547178864479065,\n",
       "   0.995781660079956,\n",
       "   0.985111653804779,\n",
       "   0.8127337098121643,\n",
       "   0.9645038843154907,\n",
       "   0.8400020599365234,\n",
       "   0.7764254808425903,\n",
       "   0.8779997825622559,\n",
       "   1.1275020837783813,\n",
       "   1.0377566814422607,\n",
       "   1.22331702709198,\n",
       "   0.7640606164932251,\n",
       "   1.1616911888122559,\n",
       "   1.1450096368789673,\n",
       "   1.2193700075149536,\n",
       "   0.9389610290527344,\n",
       "   0.6576660871505737,\n",
       "   0.7796406149864197,\n",
       "   1.3333576917648315,\n",
       "   0.7982040047645569,\n",
       "   0.7892187833786011,\n",
       "   0.7392503023147583,\n",
       "   1.0044714212417603,\n",
       "   0.9596026539802551,\n",
       "   0.92042475938797,\n",
       "   0.9459612369537354,\n",
       "   0.9071279764175415,\n",
       "   0.9953845739364624,\n",
       "   1.147060513496399,\n",
       "   1.2338120937347412,\n",
       "   0.9854015111923218,\n",
       "   0.7172792553901672,\n",
       "   1.088921308517456,\n",
       "   0.9203974604606628,\n",
       "   1.188797950744629,\n",
       "   0.9896388053894043,\n",
       "   0.9394680261611938,\n",
       "   0.7522956728935242,\n",
       "   0.7175455689430237,\n",
       "   1.05239999294281,\n",
       "   0.9543530344963074,\n",
       "   0.8260121941566467,\n",
       "   0.7362820506095886,\n",
       "   1.0363742113113403,\n",
       "   0.9267383813858032,\n",
       "   1.0135726928710938,\n",
       "   0.7596628665924072,\n",
       "   0.8967543840408325,\n",
       "   1.1347330808639526,\n",
       "   0.9567598700523376,\n",
       "   1.016921043395996,\n",
       "   1.4727439880371094,\n",
       "   0.875681459903717,\n",
       "   0.8665187358856201,\n",
       "   0.9018263816833496,\n",
       "   0.9970600605010986,\n",
       "   0.8883570432662964,\n",
       "   1.0267189741134644,\n",
       "   1.1601815223693848,\n",
       "   1.1075280904769897,\n",
       "   0.8311508297920227,\n",
       "   0.7787110209465027,\n",
       "   0.9199314713478088,\n",
       "   1.1673556566238403,\n",
       "   1.241917610168457,\n",
       "   0.8293914794921875,\n",
       "   0.8518295288085938,\n",
       "   0.7953011393547058,\n",
       "   0.8613147735595703,\n",
       "   0.8313009738922119,\n",
       "   1.5010019540786743,\n",
       "   0.7682940363883972,\n",
       "   1.1789424419403076,\n",
       "   0.9170745611190796,\n",
       "   1.5000364780426025,\n",
       "   0.8201372623443604,\n",
       "   1.0329819917678833,\n",
       "   0.8036375641822815,\n",
       "   0.8526276350021362,\n",
       "   0.9958862066268921,\n",
       "   0.8022047281265259,\n",
       "   1.06458580493927,\n",
       "   1.0358408689498901,\n",
       "   0.8762305974960327,\n",
       "   0.78685063123703,\n",
       "   1.2251015901565552,\n",
       "   0.8329232931137085,\n",
       "   0.7768474817276001,\n",
       "   0.9648625254631042,\n",
       "   0.899653971195221,\n",
       "   0.7741690874099731,\n",
       "   0.9220964908599854,\n",
       "   0.8498095870018005,\n",
       "   1.0964407920837402,\n",
       "   1.0026757717132568,\n",
       "   1.1435452699661255,\n",
       "   1.248953938484192,\n",
       "   0.8626886606216431,\n",
       "   0.9941311478614807,\n",
       "   1.254767894744873,\n",
       "   0.8727986812591553,\n",
       "   0.6887086033821106,\n",
       "   1.1696664094924927,\n",
       "   1.690239667892456,\n",
       "   0.7807751297950745,\n",
       "   1.0618300437927246,\n",
       "   1.0054492950439453,\n",
       "   0.8863951563835144,\n",
       "   0.8990936875343323,\n",
       "   1.010442852973938,\n",
       "   0.7860381603240967,\n",
       "   0.9770942330360413,\n",
       "   0.9848136305809021,\n",
       "   1.023345947265625,\n",
       "   0.8890427350997925,\n",
       "   0.9463703632354736,\n",
       "   1.1204614639282227,\n",
       "   0.8462380170822144,\n",
       "   0.8475908637046814,\n",
       "   0.8252110481262207,\n",
       "   1.0682240724563599,\n",
       "   0.8809651136398315,\n",
       "   0.7528936862945557,\n",
       "   0.9982250928878784,\n",
       "   0.7586804628372192,\n",
       "   0.9435294270515442,\n",
       "   1.1517808437347412,\n",
       "   0.7945544719696045,\n",
       "   1.0879203081130981,\n",
       "   0.9536604285240173,\n",
       "   0.9008020758628845,\n",
       "   1.1068381071090698,\n",
       "   0.836235523223877,\n",
       "   0.877536952495575,\n",
       "   1.0486030578613281,\n",
       "   1.0624197721481323,\n",
       "   0.9459706544876099,\n",
       "   0.8279772400856018,\n",
       "   0.7060579657554626,\n",
       "   1.099153995513916,\n",
       "   0.8417139649391174,\n",
       "   1.0192835330963135,\n",
       "   0.902749240398407,\n",
       "   0.7122136354446411,\n",
       "   0.6459016799926758,\n",
       "   0.8264999389648438,\n",
       "   0.8348259925842285,\n",
       "   0.6225149631500244,\n",
       "   0.8435045480728149,\n",
       "   0.906976044178009,\n",
       "   0.9191984534263611,\n",
       "   1.025727391242981,\n",
       "   1.3010330200195312,\n",
       "   0.8731207847595215,\n",
       "   0.910840630531311,\n",
       "   0.9159674048423767,\n",
       "   0.6871342062950134,\n",
       "   1.0597939491271973,\n",
       "   0.871397078037262,\n",
       "   1.14829683303833,\n",
       "   0.6511896252632141,\n",
       "   1.0603225231170654,\n",
       "   1.055248737335205,\n",
       "   0.881119966506958,\n",
       "   0.7562583684921265,\n",
       "   0.7646376490592957,\n",
       "   1.1134694814682007,\n",
       "   1.1961864233016968,\n",
       "   0.8833774328231812,\n",
       "   0.9908148646354675,\n",
       "   0.8629401922225952,\n",
       "   0.7404719591140747,\n",
       "   0.9192379117012024,\n",
       "   0.7995023727416992,\n",
       "   0.8740352988243103,\n",
       "   0.9898368716239929,\n",
       "   0.8463268280029297,\n",
       "   1.0589362382888794,\n",
       "   0.7414873838424683,\n",
       "   0.8685155510902405,\n",
       "   0.774324893951416,\n",
       "   0.9073803424835205,\n",
       "   0.7664524912834167,\n",
       "   1.1818304061889648,\n",
       "   0.857192873954773,\n",
       "   0.8495898246765137,\n",
       "   0.7036460638046265,\n",
       "   0.7926027178764343,\n",
       "   0.767676591873169,\n",
       "   0.8521870970726013,\n",
       "   0.9835639595985413,\n",
       "   0.7880275845527649,\n",
       "   1.0084336996078491,\n",
       "   0.9749616980552673,\n",
       "   1.0250483751296997,\n",
       "   0.9961775541305542,\n",
       "   1.0152429342269897,\n",
       "   0.9119833111763,\n",
       "   1.1189048290252686,\n",
       "   0.9137865304946899,\n",
       "   0.6950924396514893,\n",
       "   0.9918761849403381,\n",
       "   0.7698647975921631,\n",
       "   0.9080474376678467,\n",
       "   0.8317131996154785,\n",
       "   1.052910327911377,\n",
       "   0.8666975498199463,\n",
       "   0.8622569441795349,\n",
       "   1.0527135133743286,\n",
       "   1.1420912742614746,\n",
       "   1.0913827419281006,\n",
       "   1.0488700866699219,\n",
       "   0.8713154196739197,\n",
       "   0.9872211217880249,\n",
       "   0.9691802859306335,\n",
       "   1.214627981185913,\n",
       "   1.3302373886108398,\n",
       "   0.9016038775444031,\n",
       "   0.8422114253044128,\n",
       "   0.9626328349113464,\n",
       "   0.8277841210365295,\n",
       "   0.7645431756973267,\n",
       "   0.8019420504570007,\n",
       "   0.9114600419998169,\n",
       "   0.9084022045135498,\n",
       "   0.817074179649353,\n",
       "   0.7296440005302429,\n",
       "   0.8794291615486145,\n",
       "   0.6770393252372742,\n",
       "   0.6754302382469177,\n",
       "   0.7839154601097107,\n",
       "   0.8122119903564453,\n",
       "   0.8798818588256836,\n",
       "   0.7392552495002747,\n",
       "   1.3337219953536987,\n",
       "   0.9094708561897278,\n",
       "   0.9435843229293823,\n",
       "   0.9240955114364624,\n",
       "   0.9146604537963867,\n",
       "   0.8913496732711792,\n",
       "   1.4730496406555176,\n",
       "   1.1045949459075928,\n",
       "   0.9616503119468689,\n",
       "   0.9430033564567566,\n",
       "   1.2674853801727295,\n",
       "   0.7223259210586548,\n",
       "   0.7482473254203796,\n",
       "   1.425185203552246,\n",
       "   0.9209634065628052,\n",
       "   0.7239167094230652,\n",
       "   0.9522651433944702,\n",
       "   0.8448625206947327,\n",
       "   0.796210765838623,\n",
       "   0.7246811389923096,\n",
       "   0.9490282535552979,\n",
       "   0.7762466669082642,\n",
       "   0.8919394016265869,\n",
       "   0.8616358041763306,\n",
       "   0.9552906155586243,\n",
       "   0.8681155443191528,\n",
       "   0.8347041606903076,\n",
       "   0.7535461187362671,\n",
       "   1.1152576208114624,\n",
       "   0.7944856882095337,\n",
       "   0.9765908718109131,\n",
       "   0.8747600317001343,\n",
       "   0.8021402359008789,\n",
       "   0.7707350254058838,\n",
       "   0.7179797291755676,\n",
       "   0.7361603379249573,\n",
       "   0.8289133310317993,\n",
       "   1.0308723449707031,\n",
       "   1.0724760293960571,\n",
       "   0.7488278150558472,\n",
       "   0.9593527913093567,\n",
       "   0.7931304574012756,\n",
       "   1.0869311094284058,\n",
       "   0.7427344918251038,\n",
       "   1.028125524520874,\n",
       "   0.8892630934715271,\n",
       "   0.8654153347015381,\n",
       "   0.777765154838562,\n",
       "   1.2334880828857422,\n",
       "   0.891954243183136,\n",
       "   0.9312700629234314,\n",
       "   1.1246082782745361,\n",
       "   0.803742527961731,\n",
       "   1.182534098625183,\n",
       "   0.662072479724884,\n",
       "   1.0372602939605713,\n",
       "   0.7429108619689941,\n",
       "   0.9538357257843018,\n",
       "   0.7849987745285034,\n",
       "   1.0807729959487915,\n",
       "   1.2911782264709473,\n",
       "   0.8347511887550354,\n",
       "   0.846018373966217,\n",
       "   0.8940079212188721,\n",
       "   0.9410906434059143,\n",
       "   0.8578346967697144,\n",
       "   0.9375112652778625,\n",
       "   0.8622871041297913,\n",
       "   0.8549100160598755,\n",
       "   0.8298398852348328,\n",
       "   0.662764847278595,\n",
       "   0.9095649719238281,\n",
       "   0.819796085357666,\n",
       "   0.7313574552536011,\n",
       "   0.6805553436279297,\n",
       "   0.9184827208518982,\n",
       "   0.8775743246078491,\n",
       "   0.9245935678482056,\n",
       "   0.6006934642791748,\n",
       "   0.837480902671814,\n",
       "   1.076148271560669,\n",
       "   0.6641513705253601,\n",
       "   0.8698971271514893,\n",
       "   1.3081437349319458,\n",
       "   0.9907266497612,\n",
       "   0.8762000799179077,\n",
       "   0.8187946677207947,\n",
       "   0.7887759804725647,\n",
       "   0.8618507385253906,\n",
       "   0.8841299414634705,\n",
       "   0.9017817974090576,\n",
       "   0.82451331615448,\n",
       "   0.832922637462616,\n",
       "   0.9000752568244934,\n",
       "   0.77259761095047,\n",
       "   0.927075982093811,\n",
       "   0.934939444065094,\n",
       "   0.7660963535308838,\n",
       "   0.6816180944442749,\n",
       "   1.0188863277435303,\n",
       "   0.9677808284759521,\n",
       "   0.8825809955596924,\n",
       "   0.9166446924209595,\n",
       "   1.1127288341522217,\n",
       "   0.918046236038208,\n",
       "   1.0824038982391357,\n",
       "   0.7871713042259216,\n",
       "   1.0376399755477905,\n",
       "   0.9050526022911072,\n",
       "   1.0680468082427979,\n",
       "   0.631216287612915,\n",
       "   0.7665290832519531,\n",
       "   0.8880161643028259,\n",
       "   0.8392295837402344,\n",
       "   0.6559703350067139,\n",
       "   1.0171492099761963,\n",
       "   0.8555606603622437,\n",
       "   0.8271531462669373,\n",
       "   0.8908591270446777,\n",
       "   0.6826232075691223,\n",
       "   0.6974263787269592,\n",
       "   0.9747936129570007,\n",
       "   0.8487994074821472,\n",
       "   0.8400307297706604,\n",
       "   0.8368343710899353,\n",
       "   0.8033125996589661,\n",
       "   0.6514666080474854,\n",
       "   0.7676813006401062,\n",
       "   1.135864019393921,\n",
       "   0.670657217502594,\n",
       "   0.8115319609642029,\n",
       "   0.9980228543281555,\n",
       "   1.0421741008758545,\n",
       "   0.6362963318824768,\n",
       "   0.8411796689033508,\n",
       "   0.8434832096099854,\n",
       "   0.7980775237083435,\n",
       "   0.7014890909194946,\n",
       "   1.4574850797653198,\n",
       "   1.0120506286621094,\n",
       "   0.8004579544067383,\n",
       "   0.7453575730323792,\n",
       "   0.9748584628105164,\n",
       "   0.7583785653114319,\n",
       "   1.0260409116744995,\n",
       "   0.8853014707565308,\n",
       "   0.6702479124069214,\n",
       "   0.6221442222595215,\n",
       "   1.0134238004684448,\n",
       "   0.8778946995735168,\n",
       "   0.9160178899765015,\n",
       "   0.8380130529403687,\n",
       "   0.7747004628181458,\n",
       "   0.79105144739151,\n",
       "   0.9253563284873962,\n",
       "   0.9175395965576172,\n",
       "   0.8240072727203369,\n",
       "   0.8933871984481812,\n",
       "   0.7464770674705505,\n",
       "   0.770150899887085,\n",
       "   0.8342963457107544,\n",
       "   0.9742739796638489,\n",
       "   0.7390389442443848,\n",
       "   0.7679917812347412,\n",
       "   1.0907244682312012,\n",
       "   0.7675949335098267,\n",
       "   0.9663712978363037,\n",
       "   0.7841601371765137,\n",
       "   0.8332153558731079,\n",
       "   0.9735340476036072,\n",
       "   0.7657565474510193,\n",
       "   0.7193289399147034,\n",
       "   1.4898886680603027,\n",
       "   1.9605119228363037,\n",
       "   ...],\n",
       "  [tensor(0.0009, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.1875, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.2274, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.2480, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.2652, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.2738, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.2966, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.2958, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3240, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3153, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3337, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3335, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3479, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3492, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3444, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3508, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3615, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3737, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3681, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3702, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3591, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3683, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3760, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3791, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3836, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3696, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3892, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3823, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3920, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3972, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3767, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3906, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3949, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3893, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3926, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3973, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4006, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4027, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4069, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.3981, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4024, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4066, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4136, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4065, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4145, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4170, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4156, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4191, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4111, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4213, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4081, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4233, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4191, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4141, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4196, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4258, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4125, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4175, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4183, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4251, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4109, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4296, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4234, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4317, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4296, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4284, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4258, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4295, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4448, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4451, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4479, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4476, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4478, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4454, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4491, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4471, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4472, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4503, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4453, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.4484, device='cuda:0', dtype=torch.float64)],\n",
       "  [tensor(0.0046, device='cuda:0'),\n",
       "   tensor(0.7043, device='cuda:0'),\n",
       "   tensor(0.7610, device='cuda:0'),\n",
       "   tensor(0.7709, device='cuda:0'),\n",
       "   tensor(0.7909, device='cuda:0'),\n",
       "   tensor(0.7970, device='cuda:0'),\n",
       "   tensor(0.8118, device='cuda:0'),\n",
       "   tensor(0.8087, device='cuda:0'),\n",
       "   tensor(0.8180, device='cuda:0'),\n",
       "   tensor(0.8145, device='cuda:0'),\n",
       "   tensor(0.8278, device='cuda:0'),\n",
       "   tensor(0.8294, device='cuda:0'),\n",
       "   tensor(0.8311, device='cuda:0'),\n",
       "   tensor(0.8315, device='cuda:0'),\n",
       "   tensor(0.8348, device='cuda:0'),\n",
       "   tensor(0.8335, device='cuda:0'),\n",
       "   tensor(0.8414, device='cuda:0'),\n",
       "   tensor(0.8456, device='cuda:0'),\n",
       "   tensor(0.8419, device='cuda:0'),\n",
       "   tensor(0.8400, device='cuda:0'),\n",
       "   tensor(0.8413, device='cuda:0'),\n",
       "   tensor(0.8414, device='cuda:0'),\n",
       "   tensor(0.8454, device='cuda:0'),\n",
       "   tensor(0.8472, device='cuda:0'),\n",
       "   tensor(0.8509, device='cuda:0'),\n",
       "   tensor(0.8390, device='cuda:0'),\n",
       "   tensor(0.8517, device='cuda:0'),\n",
       "   tensor(0.8466, device='cuda:0'),\n",
       "   tensor(0.8504, device='cuda:0'),\n",
       "   tensor(0.8548, device='cuda:0'),\n",
       "   tensor(0.8459, device='cuda:0'),\n",
       "   tensor(0.8503, device='cuda:0'),\n",
       "   tensor(0.8546, device='cuda:0'),\n",
       "   tensor(0.8514, device='cuda:0'),\n",
       "   tensor(0.8542, device='cuda:0'),\n",
       "   tensor(0.8535, device='cuda:0'),\n",
       "   tensor(0.8555, device='cuda:0'),\n",
       "   tensor(0.8511, device='cuda:0'),\n",
       "   tensor(0.8549, device='cuda:0'),\n",
       "   tensor(0.8525, device='cuda:0'),\n",
       "   tensor(0.8570, device='cuda:0'),\n",
       "   tensor(0.8555, device='cuda:0'),\n",
       "   tensor(0.8590, device='cuda:0'),\n",
       "   tensor(0.8562, device='cuda:0'),\n",
       "   tensor(0.8587, device='cuda:0'),\n",
       "   tensor(0.8622, device='cuda:0'),\n",
       "   tensor(0.8598, device='cuda:0'),\n",
       "   tensor(0.8570, device='cuda:0'),\n",
       "   tensor(0.8558, device='cuda:0'),\n",
       "   tensor(0.8582, device='cuda:0'),\n",
       "   tensor(0.8596, device='cuda:0'),\n",
       "   tensor(0.8602, device='cuda:0'),\n",
       "   tensor(0.8608, device='cuda:0'),\n",
       "   tensor(0.8608, device='cuda:0'),\n",
       "   tensor(0.8583, device='cuda:0'),\n",
       "   tensor(0.8619, device='cuda:0'),\n",
       "   tensor(0.8602, device='cuda:0'),\n",
       "   tensor(0.8590, device='cuda:0'),\n",
       "   tensor(0.8596, device='cuda:0'),\n",
       "   tensor(0.8591, device='cuda:0'),\n",
       "   tensor(0.8603, device='cuda:0'),\n",
       "   tensor(0.8648, device='cuda:0'),\n",
       "   tensor(0.8616, device='cuda:0'),\n",
       "   tensor(0.8637, device='cuda:0'),\n",
       "   tensor(0.8627, device='cuda:0'),\n",
       "   tensor(0.8650, device='cuda:0'),\n",
       "   tensor(0.8634, device='cuda:0'),\n",
       "   tensor(0.8635, device='cuda:0'),\n",
       "   tensor(0.8716, device='cuda:0'),\n",
       "   tensor(0.8714, device='cuda:0'),\n",
       "   tensor(0.8716, device='cuda:0'),\n",
       "   tensor(0.8720, device='cuda:0'),\n",
       "   tensor(0.8722, device='cuda:0'),\n",
       "   tensor(0.8720, device='cuda:0'),\n",
       "   tensor(0.8706, device='cuda:0'),\n",
       "   tensor(0.8709, device='cuda:0'),\n",
       "   tensor(0.8721, device='cuda:0'),\n",
       "   tensor(0.8712, device='cuda:0'),\n",
       "   tensor(0.8700, device='cuda:0'),\n",
       "   tensor(0.8716, device='cuda:0')],\n",
       "  tensor([[8.3252e+07, 1.5266e+06, 1.5070e+05, 4.6000e+03, 7.6010e+03, 5.7230e+03,\n",
       "           0.0000e+00, 2.1560e+03, 1.9676e+04, 3.0222e+04, 9.6810e+03, 5.8825e+04,\n",
       "           1.9400e+02, 2.3558e+05, 1.0800e+02, 6.9800e+02, 1.8054e+04, 3.4800e+02,\n",
       "           1.5022e+04, 9.4873e+05],\n",
       "          [2.2981e+06, 9.0221e+06, 1.7504e+05, 7.9020e+03, 2.4143e+04, 3.1875e+04,\n",
       "           0.0000e+00, 7.7200e+02, 2.2259e+04, 6.8621e+04, 1.0000e+01, 4.7670e+04,\n",
       "           2.8000e+01, 8.4676e+04, 1.0000e+00, 1.3500e+02, 2.1520e+03, 2.0600e+02,\n",
       "           2.9089e+04, 5.6655e+05],\n",
       "          [2.0514e+05, 1.2428e+05, 4.6282e+07, 1.0950e+05, 1.6081e+05, 2.0786e+05,\n",
       "           2.4127e+04, 7.4243e+04, 1.0634e+06, 5.8000e+03, 3.9241e+05, 2.1085e+05,\n",
       "           2.2200e+02, 5.4255e+05, 1.7178e+04, 1.9926e+04, 6.4858e+04, 5.4700e+02,\n",
       "           3.5289e+04, 7.1736e+05],\n",
       "          [1.3928e+05, 7.0194e+04, 7.4797e+05, 2.6961e+05, 6.7126e+04, 8.0050e+03,\n",
       "           4.9000e+01, 2.4480e+03, 1.5434e+05, 1.1341e+04, 4.0000e+01, 3.6664e+04,\n",
       "           9.0000e+00, 5.7497e+04, 2.2300e+02, 1.6400e+02, 4.8500e+02, 3.0000e+00,\n",
       "           5.7130e+03, 1.0672e+05],\n",
       "          [1.3714e+04, 3.9334e+04, 8.1590e+05, 2.5620e+04, 5.6175e+05, 4.5062e+04,\n",
       "           1.9200e+02, 4.5000e+03, 1.1410e+05, 7.6600e+03, 1.6970e+03, 2.7929e+04,\n",
       "           7.0000e+01, 6.3854e+04, 4.3930e+03, 2.2000e+03, 3.6230e+03, 3.3700e+02,\n",
       "           1.7392e+04, 1.2932e+05],\n",
       "          [1.3976e+04, 4.7204e+04, 1.0342e+06, 3.2340e+03, 4.0674e+04, 1.6867e+06,\n",
       "           1.6284e+04, 1.7197e+04, 2.2932e+05, 8.9220e+03, 1.6120e+04, 4.9927e+04,\n",
       "           2.0000e+00, 4.4865e+04, 2.3300e+02, 9.6400e+02, 2.4520e+03, 1.6800e+02,\n",
       "           2.6168e+04, 1.5206e+05],\n",
       "          [0.0000e+00, 0.0000e+00, 1.1972e+05, 0.0000e+00, 7.0000e+01, 1.8043e+04,\n",
       "           2.3922e+05, 2.3410e+03, 4.3587e+04, 0.0000e+00, 2.0380e+03, 1.7530e+03,\n",
       "           9.0000e+00, 2.7930e+03, 1.1000e+01, 2.4000e+02, 4.6000e+01, 3.3000e+01,\n",
       "           2.2200e+02, 2.2038e+04],\n",
       "          [5.1840e+03, 3.5840e+03, 2.6892e+05, 4.0000e+00, 2.5520e+03, 1.2994e+04,\n",
       "           1.9200e+03, 9.7998e+05, 4.5011e+04, 1.2200e+02, 1.0980e+03, 1.2747e+04,\n",
       "           5.9000e+01, 2.6415e+04, 6.2280e+03, 3.8460e+03, 3.0240e+03, 1.0000e+01,\n",
       "           1.0870e+03, 1.4992e+05],\n",
       "          [4.4386e+04, 7.9274e+04, 1.1210e+06, 3.3705e+04, 5.7916e+04, 1.2092e+05,\n",
       "           1.2951e+04, 2.2293e+04, 3.7504e+07, 2.4565e+05, 1.1776e+05, 7.1933e+04,\n",
       "           6.3000e+02, 1.1377e+05, 1.9000e+01, 2.9300e+03, 1.0510e+03, 4.4800e+02,\n",
       "           2.3210e+04, 1.5982e+05],\n",
       "          [8.7068e+04, 2.4152e+05, 2.5902e+04, 2.0204e+04, 1.7481e+04, 6.4840e+03,\n",
       "           9.0000e+00, 2.5600e+02, 2.9742e+05, 1.0730e+06, 0.0000e+00, 5.4490e+03,\n",
       "           2.0000e+01, 2.1951e+04, 0.0000e+00, 1.6200e+02, 3.3000e+01, 1.0600e+02,\n",
       "           7.0220e+03, 1.0028e+05],\n",
       "          [2.4216e+04, 0.0000e+00, 1.2548e+05, 0.0000e+00, 3.0000e+00, 4.8880e+03,\n",
       "           8.7800e+02, 1.7270e+03, 8.2235e+04, 0.0000e+00, 7.4307e+06, 1.6000e+01,\n",
       "           0.0000e+00, 7.3650e+03, 2.6000e+01, 9.0000e+00, 2.9000e+02, 0.0000e+00,\n",
       "           0.0000e+00, 2.9169e+04],\n",
       "          [2.2761e+04, 2.5296e+04, 2.3194e+05, 1.2500e+02, 2.1870e+03, 1.5248e+04,\n",
       "           6.6600e+02, 2.2170e+03, 3.4429e+04, 7.2700e+02, 6.8400e+02, 2.4211e+06,\n",
       "           9.0980e+03, 9.5293e+04, 1.8630e+03, 3.0700e+02, 6.8000e+01, 4.0040e+03,\n",
       "           3.5365e+04, 7.3951e+04],\n",
       "          [1.4980e+03, 1.6970e+03, 2.2654e+04, 2.0000e+01, 1.1300e+02, 1.0910e+03,\n",
       "           4.5800e+02, 5.4100e+02, 1.0130e+04, 1.1000e+02, 5.9000e+01, 3.4548e+05,\n",
       "           1.4255e+04, 4.3028e+04, 4.3400e+02, 8.6000e+01, 0.0000e+00, 5.9610e+03,\n",
       "           3.7001e+04, 9.0030e+03],\n",
       "          [1.8990e+05, 4.7179e+04, 4.8428e+05, 3.2850e+03, 1.4957e+04, 1.6617e+04,\n",
       "           1.4690e+03, 9.3450e+03, 9.8792e+04, 9.8740e+03, 3.8994e+04, 1.6110e+05,\n",
       "           4.1250e+03, 1.3466e+07, 1.1653e+04, 3.9041e+04, 4.4207e+04, 1.3917e+04,\n",
       "           5.3543e+04, 2.1383e+05],\n",
       "          [8.7810e+03, 1.3320e+03, 2.2419e+05, 1.4060e+03, 1.3080e+03, 2.7430e+03,\n",
       "           5.1300e+02, 5.9170e+03, 1.4152e+04, 6.4000e+01, 5.0736e+04, 1.1661e+04,\n",
       "           4.6000e+01, 2.2539e+05, 1.9461e+04, 2.4695e+04, 1.8099e+04, 2.8300e+02,\n",
       "           1.3440e+03, 7.7599e+04],\n",
       "          [5.5060e+03, 9.7100e+02, 2.7905e+05, 1.9100e+02, 1.1419e+04, 8.6260e+03,\n",
       "           2.2840e+03, 1.3259e+04, 4.0678e+04, 4.4000e+01, 5.8000e+01, 8.3200e+03,\n",
       "           1.8000e+01, 2.7867e+05, 1.6207e+04, 8.2771e+04, 6.0104e+04, 2.2000e+01,\n",
       "           2.5300e+02, 8.2188e+04],\n",
       "          [4.2400e+02, 5.2700e+02, 1.3244e+05, 1.4000e+02, 2.5470e+03, 1.9670e+03,\n",
       "           1.3900e+02, 2.8500e+02, 5.6360e+03, 2.2600e+02, 2.1230e+03, 1.1880e+03,\n",
       "           0.0000e+00, 4.2653e+04, 3.3830e+03, 1.3669e+04, 2.6194e+04, 0.0000e+00,\n",
       "           3.5000e+01, 2.4315e+04],\n",
       "          [1.1010e+03, 1.1380e+03, 1.2324e+04, 6.4000e+01, 3.9500e+02, 6.7600e+02,\n",
       "           4.2000e+02, 2.3200e+02, 2.4880e+03, 1.4300e+02, 0.0000e+00, 3.0528e+04,\n",
       "           3.3720e+03, 6.8520e+04, 9.4000e+01, 8.0000e+00, 0.0000e+00, 1.7151e+04,\n",
       "           3.4536e+04, 9.1000e+03],\n",
       "          [1.2395e+04, 3.2654e+04, 8.8980e+04, 1.2500e+03, 1.2745e+04, 1.3601e+04,\n",
       "           4.5700e+02, 5.2200e+02, 3.8659e+04, 5.3750e+03, 1.4000e+01, 1.3326e+05,\n",
       "           4.6090e+03, 1.2202e+05, 3.3000e+01, 2.8000e+01, 9.0000e+00, 1.3130e+04,\n",
       "           1.0902e+06, 5.5282e+04],\n",
       "          [4.2241e+06, 1.1350e+06, 2.5086e+06, 5.0553e+04, 1.1189e+05, 1.4769e+05,\n",
       "           1.5212e+04, 1.1447e+05, 3.4432e+05, 1.2129e+05, 1.4122e+05, 2.7191e+05,\n",
       "           2.4760e+03, 4.7107e+05, 2.6631e+04, 1.7768e+04, 2.9502e+04, 5.5990e+03,\n",
       "           1.1846e+05, 2.3052e+07]], device='cuda:0', dtype=torch.float64)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.architectures.architecture_configs import *\n",
    "import src.architectures.Temporal_UNET_Template as Temporal_UNET_Template\n",
    "import src.architectures.UNet_Template as UNet_Template\n",
    "import utils.utils\n",
    "import utils\n",
    "\n",
    "\"\"\"\n",
    "# for BaselineVanillaSmallShallow\n",
    "encoder_blocks = SmallShallow_NetworkSize.encoder_blocks\n",
    "decoder_blocks = SmallShallow_NetworkSize.decoder_blocks\n",
    "\n",
    "config = Temporal_VanillaUNetConfig(\n",
    "    encoder_blocks=encoder_blocks,\n",
    "    decoder_blocks=decoder_blocks,\n",
    "    temporal_cell= Conv2dRNNCell\n",
    "    )\n",
    "\n",
    "temp_unet = Temporal_UNET_Template.Temporal_UNet(config)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# for BaselineVanillaSmallDeep\n",
    "encoder_blocks = SmallDeep_NetworkSize.encoder_blocks\n",
    "decoder_blocks = SmallDeep_NetworkSize.decoder_blocks\n",
    "\n",
    "config = Temporal_VanillaUNetConfig(\n",
    "    encoder_blocks=encoder_blocks,\n",
    "    decoder_blocks=decoder_blocks,\n",
    "    temporal_cell= Conv2dRNNCell\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "# for BaselineVanillaOriginalSizes\n",
    "encoder_blocks = Original_Dimensions.encoder_blocks\n",
    "decoder_blocks = Original_Dimensions.decoder_blocks\n",
    "\n",
    "\n",
    "config = Temporal_VanillaUNetConfig(\n",
    "        encoder_blocks=encoder_blocks,\n",
    "        decoder_blocks=decoder_blocks,\n",
    "        temporal_cell= Conv2dRNNCell\n",
    "        )\n",
    "\n",
    "unet = UNet_Template.UNet(config)\n",
    "\n",
    "unet_optim = torch.optim.Adam(unet.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "utils.utils.load_model(unet, unet_optim, \"models/UNet_Original/UNet_Original/Layers3_InitDim64cityscapes_epoch_79.pth\", \"cuda\")\n",
    "\n",
    "# epochs=100\n",
    "# temp_unet_trainer = utils.train_eval.Trainer(\n",
    "#             temp_unet, temp_unet_optim, criterion,\n",
    "#             train_loader, valid_loader, \"cityscapes\", epochs,\n",
    "#             sequence=True, all_labels=20, start_epoch=82)\n",
    "\n",
    "# load_model = True\n",
    "# if load_model:\n",
    "#     temp_unet_trainer.load_model(\"cityscapes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "@torch.no_grad()\n",
    "def vis_seq(model, loader):\n",
    "    visualizer = vis.CityscapesVisualizer()\n",
    "    model.eval()\n",
    "    for i, (imgs, targets) in enumerate(loader):\n",
    "        imgs = imgs.cuda()\n",
    "        preds = model(imgs)\n",
    "        print(preds.shape)\n",
    "        for i in range(preds.shape[0]):\n",
    "            decoded_seq = get_decoded_img_seq(preds[i])\n",
    "\n",
    "            for j in range(len(decoded_seq)):\n",
    "                plt.imshow(decoded_seq[j])\n",
    "                plt.show()\n",
    "\n",
    "            break\n",
    "        break\n",
    "    return \n",
    "\n",
    "@torch.no_grad()\n",
    "def save_vis_seq(model, loader, model_name=\"default\"):\n",
    "    if not os.path.exists(\"imgs\"):\n",
    "        os.makedirs(\"imgs\")\n",
    "    if not os.path.exists(f\"imgs/{model_name}\"):\n",
    "        os.makedirs(f\"imgs/{model_name}\")\n",
    "\n",
    "    visualizer = vis.CityscapesVisualizer()\n",
    "    model.eval()\n",
    "    for k, (imgs, targets) in enumerate(loader):\n",
    "        if not os.path.exists(f\"imgs/{model_name}/{k}\"):\n",
    "            os.makedirs(f\"imgs/{model_name}/{k}\")\n",
    "        if not os.path.exists(f\"imgs/{model_name}/{k}/original\"):\n",
    "            os.makedirs(f\"imgs/{model_name}/{k}/original\")\n",
    "        if not os.path.exists(f\"imgs/{model_name}/{k}/predicted\"):\n",
    "            os.makedirs(f\"imgs/{model_name}/{k}/predicted\")\n",
    "        imgs = imgs.cuda()\n",
    "        for i in range(imgs.shape[1]):\n",
    "            preds = model(imgs[:, i, :, :, :])\n",
    "            decoded_seq = get_decoded_img_seq(preds[0])\n",
    "            torchvision.utils.save_image(torch.from_numpy(decoded_seq.transpose(2,0,1)), os.path.join(os.getcwd(), \"imgs\", f\"{model_name}\", f\"{k}\", \"predicted\", f\"imgs_{i}.png\"))\n",
    "            mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "            std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "            unnorm_imgs = imgs.cpu() * std + mean\n",
    "\n",
    "            torchvision.utils.save_image(unnorm_imgs[:, i], os.path.join(os.getcwd(), \"imgs\", f\"{model_name}\", f\"{k}\", \"original\", f\"imgs_{i}.png\"))\n",
    "        print(k)\n",
    "\n",
    "        if k > 20:\n",
    "            break\n",
    "\n",
    "    return \n",
    "\n",
    "def get_decoded_img_seq(preds):\n",
    "    result = []\n",
    "    visualizer = vis.CityscapesVisualizer()\n",
    "    predicted_class = torch.argmax(preds, dim=1)[0]\n",
    "    decoded_pred = visualizer.decode_segmap(predicted_class.cpu().numpy())\n",
    "    result.append(decoded_pred)\n",
    "\n",
    "    #     decoded_pred = visualizer.decode_segmap(predicted_class[j].cpu().numpy())\n",
    "    #     result.append(decoded_pred)\n",
    "        #torchvision.utils.save_image(torch.from_numpy(decoded_pred.transpose(2,0,1)), os.path.join(os.getcwd(), \"imgs\", \"training\", f\"imgs_{j}.png\"))\n",
    "    return decoded_pred\n",
    "\n",
    "save_vis_seq(unet, valid_loader, model_name=\"BaselineVanillaOriginalSizes_low_res\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import PIL\n",
    "import os\n",
    "\n",
    "def create_gifs(model_name=\"default\", mode=\"side-by-side\", transparency=0.5, fps=8):\n",
    "\n",
    "    allowed_modes = [\"side-by-side\", \"overlay\"]\n",
    "    if mode not in allowed_modes:\n",
    "        raise ValueError(f\"mode must be one of {alloud_modes}\")\n",
    "    imgs_root=f\"imgs/{model_name}\"\n",
    "    dirlist = [ item for item in os.listdir(imgs_root) if os.path.isdir(os.path.join(imgs_root, item)) ]\n",
    "    # remove \"gifs\"-folder from dirlist\n",
    "    dirlist = [item for item in dirlist if item != \"gifs\"]\n",
    "\n",
    "    if not os.path.exists(f\"imgs/{model_name}/gifs\"):\n",
    "        os.makedirs(f\"imgs/{model_name}/gifs\")\n",
    "\n",
    "\n",
    "\n",
    "    if mode == \"side-by-side\":\n",
    "        for i in range(len(dirlist)):\n",
    "            images = []\n",
    "            for j in range(12):\n",
    "                original = PIL.Image.open(f\"imgs/{model_name}/{dirlist[i]}/original/imgs_{j}.png\")\n",
    "                prediction = PIL.Image.open(f\"imgs/{model_name}/{i}/predicted/imgs_{j}.png\")\n",
    "\n",
    "                (width1, height1) = original.size\n",
    "                (width2, height2) = prediction.size\n",
    "\n",
    "                result_width = width1 + width2\n",
    "                result_height = max(height1, height2)\n",
    "\n",
    "                result = PIL.Image.new('RGB', (result_width, result_height))\n",
    "                result.paste(im=original, box=(0, 0))\n",
    "                result.paste(im=prediction, box=(width1, 0))\n",
    "                images.append(result)\n",
    "            imageio.mimsave(f\"imgs/{model_name}/gifs/{i}.gif\", images, fps=fps)\n",
    "\n",
    "    elif mode == \"overlay\":\n",
    "        for i in dirlist:\n",
    "            images = []\n",
    "            for j in range(12):\n",
    "                background = PIL.Image.open(f\"imgs/{model_name}/{i}/original/imgs_{j}.png\")\n",
    "                foreground  = PIL.Image.open(f\"imgs/{model_name}/{i}/predicted/imgs_{j}.png\")\n",
    "                foreground.putalpha(int(255*(1-transparency))) \n",
    "                background.paste(foreground, (0, 0), mask=foreground)\n",
    "                images.append(background)\n",
    "            imageio.mimsave(f\"imgs/{model_name}/gifs/{i}.gif\", images, fps=fps)\n",
    "\n",
    "create_gifs(\"BaselineVanillaOriginalSizes_low_res\", mode=\"overlay\", transparency=0.45, fps=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
